@book{gelmanbda04,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Rubin, Donald B.},
  biburl = {https://www.bibsonomy.org/bibtex/2f7d7012c81d89965db2cfedf698f53c7/jwbowers},
  citeulike-article-id = {106919},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  edition = {2nd ed.},
  interhash = {9c5f4ce8c45003080aa52ac74eb4c78c},
  intrahash = {f7d7012c81d89965db2cfedf698f53c7},
  keywords = {bayesian statistics},
  publisher = {Chapman and Hall/CRC},
  timestamp = {2009-10-28T04:43:08.000+0100},
  title = {Bayesian Data Analysis},
  year = 2004
}

@article{roberts2004,
author = "Roberts, Gareth O. and Rosenthal, Jeffrey S.",
doi = "10.1214/154957804100000024",
fjournal = "Probability Surveys",
journal = "Probab. Surveys",
pages = "20--71",
publisher = "The Institute of Mathematical Statistics and the Bernoulli Society",
title = "General state space Markov chains and MCMC algorithms",
url = "https://doi.org/10.1214/154957804100000024",
volume = "1",
year = "2004"
}

@book{meynandtweedie09,
author = {Meyn, Sean and Tweedie, Richard L.},
title = {Markov Chains and Stochastic Stability},
year = {2009},
isbn = {0521731828},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd}
}

@inproceedings{cogburn1972,
address = "Berkeley, Calif.",
author = "Cogburn, Robert",
booktitle = "Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 2: Probability Theory",
pages = "485--512",
publisher = "University of California Press",
title = "The central limit theorem for Markov processes",
url = "https://projecteuclid.org/euclid.bsmsp/1200514234",
year = "1972"
}

@article{roberts1997,
author = "Roberts, Gareth and Rosenthal, Jeffrey",
doi = "10.1214/ECP.v2-981",
fjournal = "Electronic Communications in Probability",
journal = "Electron. Commun. Probab.",
pages = "13--25",
pno = "2",
publisher = "The Institute of Mathematical Statistics and the Bernoulli Society",
title = "Geometric Ergodicity and Hybrid Markov Chains",
url = "https://doi.org/10.1214/ECP.v2-981",
volume = "2",
year = "1997"
}

@article{Metropolis1953,
  added-at = {2010-08-02T15:41:00.000+0200},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  biburl = {https://www.bibsonomy.org/bibtex/25bdc169acdc743b5f9946748d3ce587b/lopusz},
  doi = {10.1063/1.1699114},
  interhash = {b67019ed11f34441c67cc69ee5683945},
  intrahash = {5bdc169acdc743b5f9946748d3ce587b},
  journal = {The Journal of Chemical Physics},
  keywords = {MonteCarlo},
  number = 6,
  pages = {1087-1092},
  publisher = {AIP},
  timestamp = {2010-08-02T15:41:00.000+0200},
  title = {Equation of State Calculations by Fast Computing Machines},
  url = {http://link.aip.org/link/?JCP/21/1087/1},
  volume = 21,
  year = 1953
}

@article{hastings70,
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.
},
  added-at = {2009-05-22T23:03:45.000+0200},
  author = {Hastings, W. K.},
  biburl = {https://www.bibsonomy.org/bibtex/2f636b3c2026f71ad7f4f6352c2175d80/mboley},
  description = {Origin of Hasting's generalization of Metropolis' algorithm.},
  doi = {10.1093/biomet/57.1.97},
  eprint = {http://biomet.oxfordjournals.org/cgi/reprint/57/1/97.pdf},
  interhash = {d8daa18a6f782f1b2e01071c453f7b4e},
  intrahash = {f636b3c2026f71ad7f4f6352c2175d80},
  journal = {Biometrika},
  keywords = {markovChains},
  number = 1,
  pages = {97-109},
  timestamp = {2009-05-22T23:03:45.000+0200},
  title = {Monte Carlo sampling methods using Markov chains and their applications},
  url = {http://biomet.oxfordjournals.org/cgi/content/abstract/57/1/97},
  volume = 57,
  year = 1970
}

@article{liang10,
author = {Liang, Faming and Liu, Chuanhai and Carroll, Raymond},
year = {2010},
month = {07},
pages = {},
title = {Advanced Markov Chain Monte Carlo Methods: Learning from Past Samples},
journal = {Advanced Markov Chain Monte Carlo Methods: Learning from Past Samples},
doi = {10.1002/9780470669723}
}

@article{sherlock2010,
author = "Sherlock, Chris and Fearnhead, Paul and Roberts, Gareth O.",
doi = "10.1214/10-STS327",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "05",
number = "2",
pages = "172--190",
publisher = "The Institute of Mathematical Statistics",
title = "The Random Walk Metropolis: Linking Theory and Practice Through a Case Study",
url = "https://doi.org/10.1214/10-STS327",
volume = "25",
year = "2010"
}

@inproceedings{Au2001EstimationOS,
  title={Estimation of Small Failure Probabilities in High Dimensions by Subset Simulation},
  author={Siu-Kui Au and James L. Beck},
  year={2001}
}

@article{zuev08,
author = {Katafygiotis, L. and Zuev, Konstantin},
year = {2008},
month = {04},
pages = {208-218},
title = {Geometric insight into the challenges of solving high-dimensional reliability problems},
volume = {23},
journal = {Probabilistic Engineering Mechanics},
doi = {10.1016/j.probengmech.2007.12.026}
}

@Book{blum2017foundations,
author = {Blum, Avrim and Hopcroft, John and Kannan, Ravi},
title = {Foundations of Data Science},
year = {2017},
month = {June},
abstract = {Computer science as an academic discipline began in the 1960’s. Emphasis was on programming languages, compilers, operating systems, and the mathematical theory that supported these areas. Courses in theoretical computer science covered finite automata, regular expressions, context-free languages, and computability. In the 1970’s, the study of algorithms was added as an important component of theory. The emphasis was on making computers useful. Today, a fundamental change is taking place and the focus is more on applications. There are many reasons for this change. The merging of computing and communications has played an important role. The enhanced ability to observe, collect, and store data in the natural sciences, in commerce, and in other fields calls for a change in our understanding of data and how to handle it in the modern setting. The emergence of the web and social networks as central aspects of daily life presents both opportunities and challenges for theory.},
url = {https://www.microsoft.com/en-us/research/publication/foundations-of-data-science-2/},
pages = {1-465},
}

@article{stan,
   author = {Bob Carpenter and Andrew Gelman and Matthew Hoffman and Daniel Lee and Ben Goodrich and Michael Betancourt and Marcus Brubaker and Jiqiang Guo and Peter Li and Allen Riddell},
   title = {Stan: A Probabilistic Programming Language},
   journal = {Journal of Statistical Software, Articles},
   volume = {76},
   number = {1},
   year = {2017},
   keywords = {probabilistic programming; Bayesian inference; algorithmic differentiation; Stan},
   abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propagation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line using the cmdstan package, through R using the rstan package, and through Python using the pystan package. All three interfaces support sampling and optimization-based inference with diagnostics and posterior analysis. rstan and pystan also provide access to log probabilities, gradients, Hessians, parameter transforms, and specialized plotting.},
   issn = {1548-7660},
   pages = {1--32},
   doi = {10.18637/jss.v076.i01},
   url = {https://www.jstatsoft.org/v076/i01}
}

@article{duane87,
title = "Hybrid Monte Carlo",
journal = "Physics Letters B",
volume = "195",
number = "2",
pages = "216 - 222",
year = "1987",
issn = "0370-2693",
doi = "https://doi.org/11.1016/0370-2693(87)91197-X",
url = "http://www.sciencedirect.com/science/article/pii/037026938791197X",
author = "Simon Duane and A.D. Kennedy and Brian J. Pendleton and Duncan Roweth",
abstract = "We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons."
}

@misc{standev2018stancore,
title = {{The Stan Core Library}},
author = {{Stan Development Team}},
note = {Version 2.18.0},
year = {2018},
url = {http://mc-stan.org/},
}

@misc{betancourt2017conceptual,
    title={A Conceptual Introduction to Hamiltonian Monte Carlo},
    author={Michael Betancourt},
    year={2017},
    eprint={1701.02434},
    archivePrefix={arXiv},
    primaryClass={stat.ME}
}

@misc{betancourt2017convergence,
    title={The Convergence of Markov chain Monte Carlo Methods: From the Metropolis method to Hamiltonian Monte Carlo},
    author={Michael Betancourt},
    year={2017},
    eprint={1706.01520},
    archivePrefix={arXiv},
    primaryClass={stat.ME}
}

\section{Monte Carlo Study}


\begin{frame}{Stan}
  \Large{
  \begin{itemize}
      \item[] \emphcol{What is Stan?} C\texttt{++} package (fast run times)\pause
      \item[] \emphcol{Use cases:} Bayesian/Maximum Likelihood estimation of statistical models\pause
      \item[] \emphcol{Interfaces:} Pystan, Rstan,Stan.jl,...
   \end{itemize}
  }
\end{frame}

\begin{frame}[fragile]{Bayesian Models with Stan}
  \begin{columns}
    \begin{column}{0.4\textwidth}
      \Large{
       \begin{align*}
          \action<+->{y_i &= \alpha + \beta_{j[i]} x_i + \epsilon_i \,,\\
          \epsilon &\sim \normal{0,1}\\[0.5em]}
          \action<+->{\beta_j &= \gamma_0 + \gamma_1 u_j + \eta_j \,,\\
          \eta  &\sim \normal{0,1}}
       \end{align*}
      }
    \end{column}

  \begin{column}{0.6\textwidth}
    \begin{onlyenv}<3>
      \begin{lstlisting}[language=Stan]
    data {
    vector[N] y;
    vector[N] x;
    vector[N] u;
    int<lower=0> J;
    int<lower=0> N; 
    int<lower=1,upper=J>
            group[N];
    }
      \end{lstlisting}
  \end{onlyenv}
    \begin{onlyenv}<4>
      \begin{lstlisting}[language=Stan]
   parameter {
   real alpha;
   real gamma_0;
   real gamma_1;
   vector[J] eta_b;
   real<lower=0> sigma_b;
   real<lower=0> sigma_y;
   }
      \end{lstlisting}
  \end{onlyenv}
    \begin{onlyenv}<5>
      \begin{lstlisting}[language=Stan]
  # model
  for (i in 1:N) {
    beta[i] = gamma_0 +
         u[i] * gamma_1 +
           eta[group[i]]

    y_hat[i] = alpha +
        x[i] * beta[i];
  }
  y ~ normal(
        y_hat, sigma_y);
      \end{lstlisting}
  \end{onlyenv}
    \begin{onlyenv}<6>
      \begin{lstlisting}[language=Stan]
  # priors
  gamma_0 ~ normal(1, 1);
  gamma_1 ~ normal(1, 1);
  eta ~ normal(0, sigma_b);
  sigma_y ~ cauchy(0, 5);
  sigma_b ~ cauchy(0, 5);
      \end{lstlisting}
  \end{onlyenv}

  \end{column}
  \end{columns}

\end{frame}

\begin{frame}{How can we be sure that we sample from the right distribution? }
  \Large{
  \begin{figure}
  \centering
  \includegraphics<1>[height=6.5cm]{graphics/single-chain-1}
  \includegraphics<2>[height=6.5cm]{graphics/single-chain-2}
  \includegraphics<3>[height=6.5cm]{graphics/single-chain-3}
  \end{figure}
  }
\end{frame}




\begin{frame}{Monitoring Convergence }
  \Large{
  %\vfill
  \begin{figure}
    \centering
    \includegraphics<1>[height=5.3 cm]{graphics/s-convergence} \pause
    \includegraphics<2->[height=5.3 cm]{graphics/m-convergence}
  \end{figure}
  %\vfill
  }
 \only<3-4>{ \begin{itemize}
     \only<3> { \item[] \emphcol{Variance of a single chain:} $$ s_m^2= \frac{1}{N-1}\sum_{n=1}^{N} (\theta_m^{(n)}-\overline{\theta}_{m} )^2$$ }
 \only<4> { \item[] \emphcol{Average within chain variance:} $$W=\frac{1}{M} \sum_{m=1}^{M} s_m^2 $$ }

\end{itemize}
} 
\end{frame}

\begin{frame}{Brooks and Gelman convergence criterium}
  \Large{

  \begin{itemize}
       \item[] \emphcol{Average Variance between chains:} $$ B/N=\frac{1}{M-1} \sum_{m=1}^{M} (\overline{\theta}_m  - \overline{\theta} )^2 $$  \pause
 \item[] \emphcol{Total Variance:} $$\widehat{\text{Var}}^+ (\theta \mid y)=\frac{N-1}{N}W+\frac{1}{N}B$$

\end{itemize}
  }
\end{frame}

\begin{frame}{Monitoring Convergence}
  \Large{
  %\vfill
  \begin{itemize}
     \item[] \emphcol{Scale Reducing Factor:} $$\widehat{R}=\sqrt{\frac{\widehat{\text{Var}}^+ (\theta \mid y)}{W}}$$  \pause
 \end{itemize}

  \begin{figure}
  \centering
  \includegraphics<2>[height=5.3cm]{graphics/failure-convergence} \pause
  \includegraphics<3>[height=5.3cm]{graphics/sucess-convergence}
  \end{figure}
  %\vfill
  }
\end{frame}

\begin{frame}{Prior Design}
 \Large{
   \begin{itemize}
   \setlength\itemsep{0.5em}
   \item[] \emphcol{Good Prior:}   $\gamma_0 \sim \normal{1,1},  \gamma_1 \sim \normal{1,1}$ \pause
   \item[] \emphcol{Bad Prior:}   $\gamma_0 \sim \normal{2,1},  \gamma_1 \sim \normal{2,1}$ \pause
   \item[] \emphcol{Weak, Bad Prior:}   $\gamma_0 \sim \normal{2,3},  \gamma_1 \sim \normal{2,3}$ \pause
   \item[] \emphcol{Flat Prior:}   $\gamma_0 \sim \mathcal{U}(-\infty,\infty) ,  \gamma_1 \sim \mathcal{U}(-\infty,\infty)$ \pause
   \item[] \emphcol{In all models:}  $\sigma_y, \sigma_b \sim \text{half-Cauchy}(0,5)$
  \end{itemize}
}
\end{frame}





\begin{frame}{Posterior Distribution - good prior }
  \Large{
  \begin{figure}
  \centering
  \includegraphics<1>[height=5.5cm]{graphics/fitting-posterior}
 \caption{Posterior Draws of $\gamma_1$ with N=200, J=10 and 300 simulations}
  \end{figure}
  %\vfill
  }
\end{frame}


\begin{frame}{What happense if we decrease the number of levels J? }
  \Large{
  \begin{figure}
  \centering
  \includegraphics<1>[height=5.5cm]{graphics/fitting-posterior-small}
 \caption{Posterior Draws of $\gamma_1$ with N=50, J=5 and 300 simulations}
  \end{figure}
  %\vfill
  }
\end{frame}


\begin{frame}{Posterior Distribution - bad prior }
  \Large{
  \begin{figure}
  \centering
  \includegraphics<1>[height=5.5cm]{graphics/nonfitting-posterior}
 \caption{Posterior Draws of $\gamma_1$ with N=200, J=10 and 300 simulations}
  \end{figure}
  }
\end{frame}

\begin{frame}{Posterior Distribution - weak, bad prior }
  \Large{
  \begin{figure}
  \centering
  \includegraphics<1>[height=5.5cm]{graphics/partfitting-posterior}
 \caption{Posterior Draws of $\gamma_1$ with N=200, J=10 and 150 simulations}
  \end{figure}
  }
\end{frame}


\begin{frame}{Not a good idea: Uniform Prior}
  \Large{
  \begin{figure}
  \centering
  \includegraphics<1>[height=5.5cm]{graphics/uni-posterior}
\caption{Posterior Draws of $\gamma_1$ with N=200, J=10 and 300 simulations}
\end{figure}
  }
\end{frame}


\begin{frame}{Increase sample size dramatically}
  \Large{
  %\vfill

  \begin{figure}
  \centering
  \includegraphics<1>[height=5.5cm]{graphics/posterior-big}
 \caption{Single posterior draw for model with wrong prior and N=500, J=50}

  \end{figure}
  }
\end{frame}

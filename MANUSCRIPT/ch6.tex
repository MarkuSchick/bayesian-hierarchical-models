%\appendix
\section{Appendix}

\subsection{Tables and Figures}

\begin{proof}[Derivation of Results in Table \ref{tab:comp_uniform_bay_ml}.]
  We know that for the problem at hand the standard maximum likelihood estimators
  and their variances are given by
  \begin{align}
    \hat{\mu}_{ML} &= \frac{1}{n} \sum_i y_i = \bar{y}\,\\
    \hat{\sigma}_{ML}^2 &= \frac{1}{n} \sum_i (y_i - \bar{y})^2 = \frac{n-1}{n} s^2\,\\
    \mathrm{I}(\mu, \sigma)^{-1} &= \sqmat{\sigma^2 / n & 0\\0&\sigma^2/(2n)} \,.
  \end{align}
  The Bayesian counterpart to the ML-Estimator is the \emph{maximum a posteriori estimate},
\end{proof}

\begin{proof}[Derivation of Results in Table \ref{tab:comp_conjugate_bay_ml}.]

\end{proof}

\begin{proof}[Derivation of Results in Table \ref{tab:vol_high_dim}]
See file \lstinline{volume.py}{} in the online appendix.
\end{proof}

\subsection{Proofs}
\begin{remark}
The proofs presented here follow \citet{gelmanbda04}; however, they are written in more detail and with more intermediate steps.
\end{remark}

\begin{proof}[Proof of Proposition \ref{prop:posterior_uniform}.]
  Consider first the object $\mu \mid \sigma^2, y$.
  We get
  \begin{align*}
    p(\mu \mid \sigma^2, y) \propto p(y \mid \mu, \sigma^2) p(\mu \mid \sigma^2) \propto p(y \mid \mu, \sigma^2) \,,
  \end{align*}
  where the last step follows as the priors are assumed to be independent.
  Note then
  \begin{align*}
    p(\mu \mid \sigma^2, y) &\propto \EXP{-\frac{1}{\sigma^2}\sum_i (y_i - \mu)^2} = \EXP{-\frac{n}{\sigma^2} \frac{1}{n}\sum_i (y_i^2 - 2y_i \mu + \mu^2)}\\
    &=\EXP{-\frac{n}{\sigma^2} (\bar{y^2} - 2 \bar{y} \mu + \mu^2)} \propto
    \EXP{-\frac{1}{\sigma^2 / n} (\mu - \bar{y})^2} \,,
  \end{align*}
  where $\bar{y^2} = \frac{1}{n}\sum_i y_i^2$ and the last step is only proportional as we switch $\bar{y^2}$ for $\bar{y}^2$.
  Note that proportionality here is with respect to $\mu$.
  We thus get $\mu \mid \sigma^2, y \sim \normal{\bar{y}, \sigma^2/n}$ as our first intermediate result.

  Consider now $\sigma \mid y$.
  As we already derived the joint posterior we can compute the marginal posterior of $\sigma^2$ by integrating out $\mu$.
  Note that $\sum_i (y_i - \mu)^2 = [(n-1)s^2 + n(\bar{y} - \mu)^2]$, where $s^2$ denotes the (unbiased) sample variance. Hence
  \begin{align*}
    p(\sigma^2 \mid y) &\propto \int p(\mu, \sigma^2 \mid y) \mathrm{d} \mu\\
    &\propto \int \sigma^{-(n+2)} \EXP{-\frac{1}{2\sigma^2}\sum_i (y_i - \mu)^2} \mathrm{d} \mu\\
    &= \sigma^{-(n+2)} \int \EXP{-\frac{1}{2\sigma^2}\sum_i (y_i - \mu)^2} \mathrm{d} \mu\\
    &= \sigma^{-(n+2)} \int \EXP{-\frac{1}{2\sigma^2}[(n-1) s^2 + n(\bar{y} - \mu)^2]} \mathrm{d} \mu\\
    &= \sigma^{-(n+2)} \EXP{-\frac{1}{2\sigma^2}[(n-1) s^2]} \int \EXP{\frac{1}{2\sigma^2/n}(\mu - \bar{y})^2} \mathrm{d} \mu\\
    &= \sigma^{-(n+2)} \EXP{-\frac{1}{2\sigma^2}[(n-1) s^2]} \sqrt{2 \pi \sigma^2 / n} \\
    &\propto (\sigma^2)^{-(n+1)/2} \EXP{-\frac{1}{2\sigma^2}[(n-1) s^2]} \,,
  \end{align*}
  where the second to last step follows simply by considering the constant of integration of the normal distribution of $\mu \mid \sigma^2, y$.
  Note that here we consider proportionality with respect to $\sigma^2$.
  By inspection we see that $\sigma^2 \mid y \sim \text{scaled-Inv-} \chi^2(n-1, s^2)$, which proves our first claim.

  To finish the proof we integrate the joint posterior over $\sigma^2$ to get the marginal posterior of $\mu$.
  We evaluate the integral by substitution using
  $z = \sfrac{a}{2 \sigma^2}$ with $a = (n-1)s^2 + n(\mu - \bar{y})^2$.

  Then,
  \begin{align*}
    p(\mu \mid y) &= \int_{(0, \infty)} p(\mu, \sigma^2 \mid y) \mathrm{d}\sigma^2\\
    &\propto  \int_{(0, \infty)} (\sigma^2)^{-(n+2)/2} \EXP{-\frac{1}{2\sigma^2}[(n-1) s^2 + n(\mu - \bar{y})^2]} \mathrm{d} \sigma^2\\
    &\propto \int_{(0, \infty)} (\sigma^2)^{-(n+2)/2}\EXP{-z} [(\sigma^2)^2 / a] \mathrm{d}z\\
    &= \int_{(0, \infty)} (\sigma^2)^{-(n-2)/2} / a \EXP{-z} \mathrm{d}z\\
    &= a^{-n/2}\int_{(0, \infty)} z^{(n-2)/2}\EXP{-z} \mathrm{d}z\\
    &= a^{-n/2} \, \Gamma(n/2)\\
    &\propto a^{-n/2}\\
    &= [(n-1)s^2 + n(\mu - \bar{y})^2]^{-n/2}\\
    &\propto \left[1 + \frac{1}{n-1} \frac{(\mu - \bar{y})^2}{s^2 / n}\right]^{-n/2} \,
  \end{align*}
  where $\Gamma$ denotes the gamma function (which is finite on the positive real numbers).
  This concludes our first analysis by implying that $\mu \mid y \sim t_{n-1}(\bar{y}, s^2/n)$,
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:posterior_conjugate}.]

\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:marginal_posterior}.]

\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:hierarchical_posterior}.]

\end{proof}
